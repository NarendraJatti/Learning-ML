https://ml-playground.com/ 

https://teachablemachine.withgoogle.com/

https://www.elementsofai.com/
 
 narrow AI 
 General AI 
 ML >>AI 
 deep learning ,neural network >> ML 

 types of ML
 ===========
 suprevised >>data,label 
 classification>>binary and multi classification
 regression>>how many,how much ?
 unsupervised >no label,need to define outputs
create cluster,groups ,we need to provide label (or create groups/cluster)
 transfer learning 

 reinforcement (skill acquistion,realtime learning,rewards,penaliteis)
   

   ML algos>>called models 

   data types
   ========
   1)strucutred data ,excel,csv,format defined ,numbers 
   2)unstrcutured data ,images,videos,phonecalls,not numbers

types of evaluation (metrics)
=========
classification >>accuracy,precison,recall 
regression >MAE,MSE,RMSE 
recomendation > precison at K


faetures in data 
===========
info about data ,forms of data 
numerical faetures
categroical faetures(words)
dervied(new) feature(data)>feature enginerring 

feature coveraage >>sample data should have better data/feature spread,should avoid skewed data/features.
atelast 10 per coveraage


modelling >1)splitting data
========
based on data and problem>>decide which model(algo) to use 
Train,validate(tunning) and test >>3 sets in model 
> choosing and traning a model
> tunning a model 
> model comparision 


modelling >2)picking the model
========
prebuilt ml models 
strucutred data >>best models are xboost ,random forest,cat boost better.
unstrcutured data >>deep learning ,neural networks,transfer learning



modelling >3)tunning
========
hypermaters>>to improve model perfomrance 
improve 
randome forest > nbr of trees adjustment
neural networks>layer adjustment 


modelling >4)comparision
========
using test data
overfitting(test data leak into train data) > test data model outomce better than train data model outcome 
underfitting(data mismatch)>test data model outomce worse than train data model outcome 
over and underfitting >>due to data lekage
balanced > goldilocks zone ,try to keep outcome features not high

Overfitting and Underfitting Definitions
Before we get into the experimentation side of things, it's worth having a little reminder of overfitting and underfitting are.

All experiments should be conducted on different portions of your data.

Training data set — Use this set for model training, 70–80% of your data is the standard.

Validation/development data set — Use this set for model hyperparameter tuning and experimentation evaluation, 10–15% of your data is the standard.

Test data set — Use this set for model testing and comparison, 10–15% of your data is the standard.

These amounts can fluctuate slightly, depending on your problem and the data you have.

Poor performance on training data means the model hasn’t learned properly and is underfitting. Try a different model, improve the existing one through hyperparameter or collect more data.

Great performance on the training data but poor performance on test data means your model doesn’t generalize well. Your model may be overfitting the training data. Try using a simpler model or making sure your the test data is of the same style your model is training on.

Another form of overfitting can come in the form of better performance on test data than training data. This may mean your testing data is leaking into your training data (incorrect data splits) or you've spent too much time optimizing your model for the test set data. Ensure your training and test datasets are kept separate at all times and avoid optimizing a models performance on the test set (use the training and validation sets for model improvement).

Poor performance once deployed (in the real world) means there’s a difference in what you trained and tested your model on and what is actually happening. Ensure the data you're using during experimentation matches up with the data you're using in production.



 experimentation
 =======
 anaconda 

scikit learn(sklearn) >>ML library 
=========
in built ML model(function/algo)
methods to evaluate 


A pipeline in scikit-learn is a way to chain multiple data processing steps and a final estimator (model) into a single object. It allows you to organize your machine learning workflow in a clean, reproducible, and efficient manner.